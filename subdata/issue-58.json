{"url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3593", "repository_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT", "labels_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3593/labels{/name}", "comments_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3593/comments", "events_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3593/events", "html_url": "https://github.com/Significant-Gravitas/Auto-GPT/issues/3593", "id": 1690068858, "node_id": "I_kwDOJKSTjM5kvGd6", "number": 3593, "title": "Separation of execution and planning into different agents", "user": {"login": "dschonholtz", "id": 15002691, "node_id": "MDQ6VXNlcjE1MDAyNjkx", "avatar_url": "https://avatars.githubusercontent.com/u/15002691?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dschonholtz", "html_url": "https://github.com/dschonholtz", "followers_url": "https://api.github.com/users/dschonholtz/followers", "following_url": "https://api.github.com/users/dschonholtz/following{/other_user}", "gists_url": "https://api.github.com/users/dschonholtz/gists{/gist_id}", "starred_url": "https://api.github.com/users/dschonholtz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dschonholtz/subscriptions", "organizations_url": "https://api.github.com/users/dschonholtz/orgs", "repos_url": "https://api.github.com/users/dschonholtz/repos", "events_url": "https://api.github.com/users/dschonholtz/events{/privacy}", "received_events_url": "https://api.github.com/users/dschonholtz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 5272676243, "node_id": "LA_kwDOJKSTjM8AAAABOkankw", "url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/labels/enhancement", "name": "enhancement", "color": "a2eeef", "default": true, "description": "New feature or request"}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2023-04-30T20:23:22Z", "updated_at": "2023-05-01T21:30:46Z", "closed_at": null, "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "### Duplicates\r\n\r\n- [X] I have searched the existing issues\r\n\r\n### Summary \ud83d\udca1\r\n\r\nThe core problem here is the plan must be inferred by past work via memories and it is not clear to the user or the agent how much of the plan was actually accomplished by a given command. Ideally, this would be explicit.\r\n\r\nSo given a task from the user (or a list of goals) The task planner agent will make a list of next tasks to do with their completion status.\r\n\r\nThen we will store these tasks in a queue and pop off the first one with all dependencies done and give it to an execution agent.\r\nThe execution agent eventually should have a minified task command set for the problem to reduce unnecessary and incorrect commands, but for now, it will just execute with the agent it currently uses in the main execution loop.\r\n\r\nConcretely here this is from an architecture perspective. \r\n\r\nThe user enters a task they wish the agent to do.\r\n\r\nWe add a new class called TaskManagerLLM.\r\nAs we enter chat.py the objective and current task list if there is one is fed into taskManagerLLM and an empty initial result is fed into it.\r\nTask manager LLM creates up to 7 tasks it should do to accomplish this task. It numbers them with priority and marks dependencies where dependencies are based off of a linked list pointer structure. It also will have the specific command that should be used for each of them. It will not have in it what parameters are to that command though.\r\n\r\nIt's prompt should be very similar to the existing execution agent with the following components:\r\nThoughts:\r\nReasoning:\r\nTask List in JSON\r\nCriticism:\r\nSpeak:\r\nTask List JSON.\r\n\r\nWe then extract that JSON using our existing JSON parsing toolset.\r\nSort the created tasks without dependencies and then pick the top one. \r\nGive that task to an execution agent.\r\n\r\nAn execution agent will function the same way that an existing agent does. It will make a plan for it's very simple  (by comparison task.)\r\nThe execution agent will do a one shot evaluation with the \"smart\" model to generate the given command with the correct params.\r\nTo support this, we will first generate relevant context for it by having one more previous command to an LLM that takes in the output from the planning agent, and the goal, and the given task that has been selected and the results from previously completed tasks and have it output a prompt for the agent that succinctly describes the problem the agent is solving by executing that command.\r\n\r\nThe biggest potential problem with this is having this function with summation based or vectorized based memory.\r\n\r\nFor now, each completed task would get added to memory with the reasoning associated with it.\r\n\r\nIt is possible that the above is overly complex, and we just need an ordered task list based on commands in the planning step and its summarization memory. I might implement that first and see how it does.\r\n\r\n### Examples \ud83c\udf08\r\n\r\nOne example of a specific implementation can be found here: https://github.com/yoheinakajima/babyagi/blob/main/classic/BabyBeeAGI\r\n\r\n\r\n### Motivation \ud83d\udd26\r\n\r\nWe have a lot of performance degradation for a few reasons. Myself, and a few of the other people doing benchmarks have kind of realized that it isn't useful to do benchmarks at this point because they mostly just show how unreliable the agent is. No point in doing token counting for instance if the agent only finishes the simplist tasks 50% of the time.\r\n\r\nA lot of the problems with memory and elsewhere is the fact that we have all of this random crap that isn't relevant to the current task and we don't really process well with respect to planning what our next task is, or plan well for next task should be, or really process what our previous tasks accomplished were. And we spend a lot of precious token real estate on stuff that is mostly just confusing to the agent.\r\n\r\nThe basic thought is, if you have a call to an agent that maintains a list of tasks done, their results and what tasks should be accomplished next, and another separate execution agent, that takes that output and then executes on it for a simple task you should get far better performance. \r\n\r\nEventually, I would want to make all of the details for each task queryable so that if previous similar tasks have been executed before, we could feed that into the execution agent, but currently I think I want to keep an initial PR simple. \r\nSo my hope is to work on this, and then circle back around and show we can actually finish some benchmarks reliably", "reactions": {"url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3593/reactions", "total_count": 4, "+1": 3, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 1, "eyes": 0}, "timeline_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3593/timeline", "performed_via_github_app": null, "state_reason": null}