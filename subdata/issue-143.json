{"url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3393", "repository_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT", "labels_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3393/labels{/name}", "comments_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3393/comments", "events_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3393/events", "html_url": "https://github.com/Significant-Gravitas/Auto-GPT/issues/3393", "id": 1686472444, "node_id": "I_kwDOJKSTjM5khYb8", "number": 3393, "title": "Expanding Auto-GPT to accept multi-modality input to reach humanoid robot level", "user": {"login": "bharathraja", "id": 866896, "node_id": "MDQ6VXNlcjg2Njg5Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/866896?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bharathraja", "html_url": "https://github.com/bharathraja", "followers_url": "https://api.github.com/users/bharathraja/followers", "following_url": "https://api.github.com/users/bharathraja/following{/other_user}", "gists_url": "https://api.github.com/users/bharathraja/gists{/gist_id}", "starred_url": "https://api.github.com/users/bharathraja/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bharathraja/subscriptions", "organizations_url": "https://api.github.com/users/bharathraja/orgs", "repos_url": "https://api.github.com/users/bharathraja/repos", "events_url": "https://api.github.com/users/bharathraja/events{/privacy}", "received_events_url": "https://api.github.com/users/bharathraja/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2023-04-27T09:26:59Z", "updated_at": "2023-05-02T03:14:55Z", "closed_at": null, "author_association": "NONE", "active_lock_reason": null, "body": "### Duplicates\r\n\r\n- [X] I have searched the existing issues\r\n\r\n### Summary \ud83d\udca1\r\n\r\nCan the auto-GPT be expanded to take in multi-modality input such as image, audio, touch and can act through the humanoid robot body ? The modularization of image object recognition, audio-text processing and touch based input tokenisation into text format would integrate all senses. This would make truly autonomous humanoid robots. this can be tested in the simulated environments like OpenAI gym initially. \r\n\r\nThere are literature which has expanded GPT ability to human action sequences, like this one: https://actiongpt.github.io/\r\n\r\n### Examples \ud83c\udf08\r\n\r\n_No response_\r\n\r\n### Motivation \ud83d\udd26\r\n\r\ni-Robot movie", "reactions": {"url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3393/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3393/timeline", "performed_via_github_app": null, "state_reason": null}