{"url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3446", "repository_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT", "labels_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3446/labels{/name}", "comments_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3446/comments", "events_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3446/events", "html_url": "https://github.com/Significant-Gravitas/Auto-GPT/issues/3446", "id": 1687783162, "node_id": "I_kwDOJKSTjM5kmYb6", "number": 3446, "title": "Reducing momery size for very large and complex tasks using ChatGPT to summarize the memory", "user": {"login": "jaykay9999", "id": 74210873, "node_id": "MDQ6VXNlcjc0MjEwODcz", "avatar_url": "https://avatars.githubusercontent.com/u/74210873?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jaykay9999", "html_url": "https://github.com/jaykay9999", "followers_url": "https://api.github.com/users/jaykay9999/followers", "following_url": "https://api.github.com/users/jaykay9999/following{/other_user}", "gists_url": "https://api.github.com/users/jaykay9999/gists{/gist_id}", "starred_url": "https://api.github.com/users/jaykay9999/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jaykay9999/subscriptions", "organizations_url": "https://api.github.com/users/jaykay9999/orgs", "repos_url": "https://api.github.com/users/jaykay9999/repos", "events_url": "https://api.github.com/users/jaykay9999/events{/privacy}", "received_events_url": "https://api.github.com/users/jaykay9999/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 5272676243, "node_id": "LA_kwDOJKSTjM8AAAABOkankw", "url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/labels/enhancement", "name": "enhancement", "color": "a2eeef", "default": true, "description": "New feature or request"}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2023-04-28T02:12:49Z", "updated_at": "2023-04-30T08:24:54Z", "closed_at": null, "author_association": "NONE", "active_lock_reason": null, "body": "### Duplicates\r\n\r\n- [X] I have searched the existing issues\r\n\r\n### Summary \ud83d\udca1\r\n\r\nThe idea is when a task is very large, Rather than removing past token from the memory, ChatGPT can create a short detailed summary of the tasks done including set of actions, goals, deliverables.. etc.\r\n\r\nThe goal is to increase the long term memory through understanding the context of the memory, then create a summary of it rather than treating it as embedding of multiple words. say each 1000 word can be reduced to a summary of only 200 without losing context.\r\n\r\nI'am currently working on a project in which ChatGPT automatically reads ocr text from multiple PDF files (which is very large data) to help companies take decisions, and that was the approach i took to not lose context when very large data is being inputted.\r\n\r\n\r\nemail : jasemkhlifi@gmail.com\r\n\r\n### Examples \ud83c\udf08\r\n\r\nThe following screenshot shows an example of a function that takes ocr text data from a 32 pages long pdf. the function \"important_info_extraction()\" takes an ocr text of a page and creates a 70 tokens long summary of that page. then the summaries of all the pages are stored in a variable that does not exceed 70x32 tokens. that variable is then passed to a different prompt that will analyze the full 32 pages long pdf files to provide analysis, risk factors, decision making, etc... \r\n\r\nThe same logic can be applied for AutoGPT to be used only when the memory becomes full and some tokens are going to be removed. (it can even used for a sub part \"the older memories\" only rather then the whole memory)\r\n\r\n![Screenshot 2023-04-28 030144](https://user-images.githubusercontent.com/74210873/235036626-d0341bdc-9514-4594-abed-38c5f96f958b.png)\r\n\r\n\r\n### Motivation \ud83d\udd26\r\n\r\nI have multiple ideas and architectures to use for this specific feature and I would really love to contact anyone to further discuss this feature and I would do my best to work on it. \r\n\r\nI also have multiple other ideas but much more complex (such as creating an super agent who creates multiple agents) but that is for the future. \r\n\r\nIf something would change the world in future, it is autonomous artificial general intelligence that exponentially scales. I would love to be a part of it :)", "reactions": {"url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3446/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3446/timeline", "performed_via_github_app": null, "state_reason": null}