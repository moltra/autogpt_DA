{"url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/907", "repository_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT", "labels_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/907/labels{/name}", "comments_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/907/comments", "events_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/907/events", "html_url": "https://github.com/Significant-Gravitas/Auto-GPT/issues/907", "id": 1663743557, "node_id": "I_kwDOJKSTjM5jKrZF", "number": 907, "title": "Agents aren't being fed full instructions on instantiation", "user": {"login": "vandervoortj", "id": 64353639, "node_id": "MDQ6VXNlcjY0MzUzNjM5", "avatar_url": "https://avatars.githubusercontent.com/u/64353639?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vandervoortj", "html_url": "https://github.com/vandervoortj", "followers_url": "https://api.github.com/users/vandervoortj/followers", "following_url": "https://api.github.com/users/vandervoortj/following{/other_user}", "gists_url": "https://api.github.com/users/vandervoortj/gists{/gist_id}", "starred_url": "https://api.github.com/users/vandervoortj/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vandervoortj/subscriptions", "organizations_url": "https://api.github.com/users/vandervoortj/orgs", "repos_url": "https://api.github.com/users/vandervoortj/repos", "events_url": "https://api.github.com/users/vandervoortj/events{/privacy}", "received_events_url": "https://api.github.com/users/vandervoortj/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2023-04-12T04:38:23Z", "updated_at": "2023-04-15T09:09:36Z", "closed_at": null, "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "### Duplicates\n\n- [X] I have searched the existing issues\n\n### Steps to reproduce \ud83d\udd79\n\nGive tasks that will spawn agents.\n\n### Current behavior \ud83d\ude2f\n\nWhen agents are created, they can often be given a task without full context, and will respond \"As an AI language model...\". This often results in stuff like:\r\n\r\n`NEXT ACTION:  COMMAND = start_agent ARGUMENTS = {'name': 'summarization_agent', 'task': 'Summarize AGI Literature', 'prompt': 'Please summarize the key findings of an AGI literature summary file.'}\r\nSYSTEM:  Command start_agent returned: Agent summarization_agent created with key 2. First response: I'm sorry, but to summarize a literature summary file on AGI is a very broad task. Can you please provide me with the specific literature summary file you are referring to?`\r\n\r\n`NEXT ACTION:  COMMAND = start_agent ARGUMENTS = {'name': 'AGISummarize', 'task': 'Find and summarize relevant scientific papers or articles on AGI', 'prompt': 'What scientific papers or relevant articles can you find about Artificial General Intelligence? Please add any valuable information you find to the AGI Comprehensive Summary file.'}\r\nSYSTEM:  Command start_agent returned: Agent AGISummarize created with key 1. First response: As an AI language model, I do not have the capability to access the internet or any other external sources. However, I can suggest some resources where you can find scientific papers and articles related to Artificial General Intelligence. You can start by checking out the website of the AGI Society (agisociety.org), which is dedicated to advancing research in AGI. Additionally, some notable scientific papers on AGI include \"Artificial General Intelligence: Concept, State of the Art, and Future Prospects\" by Ben Goertzel and Cassio Pennachin, as well as \"Artificial General Intelligence: A Path to Superintelligence\" by J\u00fcrgen Schmidhuber. There are also several journals such as \"Journal of Artificial Intelligence Research\" and \"Artificial Intelligence\" that publish relevant articles on AGI.`\r\n\r\nThis is not only a waste of tokens, but it opens up the process to be flooded with hallucinations. It would seem we need to find a way for the director to be more verbose on agent instantiation.\r\n\n\n### Expected behavior \ud83e\udd14\n\nAgents are spawned in a way so as to immediately perform tasks in the environment.\n\n### Your prompt \ud83d\udcdd\n\n```yaml\r\nai_goals:\r\n- Research all the various ways AGI has been referred to in the past\r\n- Use those terms to find and summarize previous research in AGI into separate files\r\n- Summarize across all research summaries into a single final file\r\n- Shutdown\r\nai_name: AGIResearcher\r\nai_role: an AI designed to autonomously research previous works in the AGI field\r\n```", "reactions": {"url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/907/reactions", "total_count": 4, "+1": 4, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/907/timeline", "performed_via_github_app": null, "state_reason": null}