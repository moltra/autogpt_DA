{"url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/789", "repository_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT", "labels_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/789/labels{/name}", "comments_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/789/comments", "events_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/789/events", "html_url": "https://github.com/Significant-Gravitas/Auto-GPT/issues/789", "id": 1662226329, "node_id": "I_kwDOJKSTjM5jE4-Z", "number": 789, "title": "Risk-avoiding continuous mode", "user": {"login": "jnt0rrente", "id": 79209573, "node_id": "MDQ6VXNlcjc5MjA5NTcz", "avatar_url": "https://avatars.githubusercontent.com/u/79209573?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jnt0rrente", "html_url": "https://github.com/jnt0rrente", "followers_url": "https://api.github.com/users/jnt0rrente/followers", "following_url": "https://api.github.com/users/jnt0rrente/following{/other_user}", "gists_url": "https://api.github.com/users/jnt0rrente/gists{/gist_id}", "starred_url": "https://api.github.com/users/jnt0rrente/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jnt0rrente/subscriptions", "organizations_url": "https://api.github.com/users/jnt0rrente/orgs", "repos_url": "https://api.github.com/users/jnt0rrente/repos", "events_url": "https://api.github.com/users/jnt0rrente/events{/privacy}", "received_events_url": "https://api.github.com/users/jnt0rrente/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2023-04-11T10:47:51Z", "updated_at": "2023-04-30T12:18:33Z", "closed_at": null, "author_association": "NONE", "active_lock_reason": null, "body": "### Duplicates\r\n\r\n- [X] I have searched the existing issues\r\n\r\n### Summary \ud83d\udca1\r\n\r\nWhen in risk-avoiding mode, one more GPT call should be made before running each command, asking it to moderate the would-be next command. Ideally, the call would return a value on a specific range we can compare with a user-defined risk threshold. If the risk exceeds the threshold, pause execution and await human feedback.\r\n\r\n### Examples \ud83c\udf08\r\n\r\nThe intermediate call can be prompted as something on the lines of \r\n\r\n> S: You are a moderation agent tasked with reviewing potential actions of an autonomous agent. You will be given a command to review, and you are to evaluate said command on a risk scale from 0 to 100, where 0 is <competely harmless thing> and 100 is <extinction event>.\r\n> U: COMMAND: <POST call on sensitive API>\r\n\r\n### Motivation \ud83d\udd26\r\n\r\nThere is currently no way to attempt properly using AutoGPT without either babysitting or taking the risk of giving it free, unmonitored agency.\r\n\r\nThis feature would allow users to put some more trust on AutoGPT and \"letting it loose\" while trusting on its own self-moderation capabilities.", "reactions": {"url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/789/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/789/timeline", "performed_via_github_app": null, "state_reason": null}