{"url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3215", "repository_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT", "labels_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3215/labels{/name}", "comments_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3215/comments", "events_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3215/events", "html_url": "https://github.com/Significant-Gravitas/Auto-GPT/issues/3215", "id": 1683167214, "node_id": "I_kwDOJKSTjM5kUxfu", "number": 3215, "title": "openai.error.InvalidRequestError: This is not a chat model and thus not supported in the v1/chat/completions endpoint. Did you mean to use v1/completions?", "user": {"login": "zsmj610", "id": 19245461, "node_id": "MDQ6VXNlcjE5MjQ1NDYx", "avatar_url": "https://avatars.githubusercontent.com/u/19245461?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zsmj610", "html_url": "https://github.com/zsmj610", "followers_url": "https://api.github.com/users/zsmj610/followers", "following_url": "https://api.github.com/users/zsmj610/following{/other_user}", "gists_url": "https://api.github.com/users/zsmj610/gists{/gist_id}", "starred_url": "https://api.github.com/users/zsmj610/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zsmj610/subscriptions", "organizations_url": "https://api.github.com/users/zsmj610/orgs", "repos_url": "https://api.github.com/users/zsmj610/repos", "events_url": "https://api.github.com/users/zsmj610/events{/privacy}", "received_events_url": "https://api.github.com/users/zsmj610/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 5347563882, "node_id": "LA_kwDOJKSTjM8AAAABPr1Zag", "url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/labels/setup", "name": "setup", "color": "E1BC6F", "default": false, "description": "Issues with getting Auto-GPT setup on local machines"}, {"id": 5419307242, "node_id": "LA_kwDOJKSTjM8AAAABQwQQ6g", "url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/labels/needs%20info", "name": "needs info", "color": "74650E", "default": false, "description": ""}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2023-04-25T13:21:27Z", "updated_at": "2023-04-25T17:23:48Z", "closed_at": null, "author_association": "NONE", "active_lock_reason": null, "body": "### \u26a0\ufe0f Search for existing issues first \u26a0\ufe0f\n\n- [X] I have searched the existing issues, and there is no existing issue for my problem\n\n### Which Operating System are you using?\n\nWindows\n\n### Which version of Auto-GPT are you using?\n\nLatest Release\n\n### GPT-3 or GPT-4?\n\nGPT-3.5\n\n### Steps to reproduce \ud83d\udd79\n\n1.  install anaconda\r\n2. conda creat -n  new_env  python=3.10\r\n3.  download the latest version auto-gpt\r\n4.  configure the openai api_key\r\n5. python -m autogpt\r\n6. any question will lead the problem\n\n### Current behavior \ud83d\ude2f\n\n_No response_\n\n### Expected behavior \ud83e\udd14\n\n_No response_\n\n### Your prompt \ud83d\udcdd\n\n```yaml\r\nAI Name: testAI\r\ntestAI here!  I am at your service.\r\nDescribe your AI's role:  For example, 'an AI designed to autonomously develop and run businesses with the sole goal of increasing your net worth.'\r\ntestAI is: an AI designed to autonomously make a product design\r\nEnter up to 5 goals for your AI:  For example: Increase net worth, Grow Twitter Account, Develop and manage multiple businesses autonomously'\r\nEnter nothing to load defaults, enter nothing when finished.\r\nGoal 1: Determine product direction\r\nGoal 2: Sort out product features\r\nGoal 3:\r\n```\r\n\n\n### Your Logs \ud83d\udcd2\n\n```log\r\nUsing memory of type:  LocalCache\r\nUsing Browser:  chrome\r\nTraceback (most recent call last):\r\n  File \"D:\\anaconda3\\envs\\auto_gpt\\lib\\runpy.py\", line 196, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"D:\\anaconda3\\envs\\auto_gpt\\lib\\runpy.py\", line 86, in _run_code\r\n    exec(code, run_globals)\r\n  File \"E:\\Auto-GPT-0.2.2\\autogpt\\__main__.py\", line 5, in <module>\r\n    autogpt.cli.main()\r\n  File \"D:\\anaconda3\\envs\\auto_gpt\\lib\\site-packages\\click\\core.py\", line 1130, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"D:\\anaconda3\\envs\\auto_gpt\\lib\\site-packages\\click\\core.py\", line 1055, in main\r\n    rv = self.invoke(ctx)\r\n  File \"D:\\anaconda3\\envs\\auto_gpt\\lib\\site-packages\\click\\core.py\", line 1635, in invoke\r\n    rv = super().invoke(ctx)\r\n  File \"D:\\anaconda3\\envs\\auto_gpt\\lib\\site-packages\\click\\core.py\", line 1404, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"D:\\anaconda3\\envs\\auto_gpt\\lib\\site-packages\\click\\core.py\", line 760, in invoke\r\n    return __callback(*args, **kwargs)\r\n  File \"D:\\anaconda3\\envs\\auto_gpt\\lib\\site-packages\\click\\decorators.py\", line 26, in new_func\r\n    return f(get_current_context(), *args, **kwargs)\r\n  File \"E:\\Auto-GPT-0.2.2\\autogpt\\cli.py\", line 151, in main\r\n    agent.start_interaction_loop()\r\n  File \"E:\\Auto-GPT-0.2.2\\autogpt\\agent\\agent.py\", line 75, in start_interaction_loop\r\n    assistant_reply = chat_with_ai(\r\n  File \"E:\\Auto-GPT-0.2.2\\autogpt\\chat.py\", line 159, in chat_with_ai\r\n    assistant_reply = create_chat_completion(\r\n  File \"E:\\Auto-GPT-0.2.2\\autogpt\\llm_utils.py\", line 93, in create_chat_completion\r\n    response = openai.ChatCompletion.create(\r\n  File \"D:\\anaconda3\\envs\\auto_gpt\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\r\n    return super().create(*args, **kwargs)\r\n  File \"D:\\anaconda3\\envs\\auto_gpt\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 153, in create\r\n    response, _, api_key = requestor.request(\r\n  File \"D:\\anaconda3\\envs\\auto_gpt\\lib\\site-packages\\openai\\api_requestor.py\", line 226, in request\r\n    resp, got_stream = self._interpret_response(result, stream)\r\n  File \"D:\\anaconda3\\envs\\auto_gpt\\lib\\site-packages\\openai\\api_requestor.py\", line 619, in _interpret_response\r\n    self._interpret_response_line(\r\n  File \"D:\\anaconda3\\envs\\auto_gpt\\lib\\site-packages\\openai\\api_requestor.py\", line 682, in _interpret_response_line\r\n    raise self.handle_error_response(\r\nopenai.error.InvalidRequestError: This is not a chat model and thus not supported in the v1/chat/completions endpoint. Did you mean to use v1/completions?\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3215/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3215/timeline", "performed_via_github_app": null, "state_reason": null}