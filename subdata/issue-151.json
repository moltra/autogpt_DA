{"url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3367", "repository_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT", "labels_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3367/labels{/name}", "comments_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3367/comments", "events_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3367/events", "html_url": "https://github.com/Significant-Gravitas/Auto-GPT/issues/3367", "id": 1685887317, "node_id": "I_kwDOJKSTjM5kfJlV", "number": 3367, "title": "Auto-switch to gpt-35-turbo, gpt-4 and gpt-4-32k when number of tokens exceeded by query", "user": {"login": "NKT00", "id": 24981406, "node_id": "MDQ6VXNlcjI0OTgxNDA2", "avatar_url": "https://avatars.githubusercontent.com/u/24981406?v=4", "gravatar_id": "", "url": "https://api.github.com/users/NKT00", "html_url": "https://github.com/NKT00", "followers_url": "https://api.github.com/users/NKT00/followers", "following_url": "https://api.github.com/users/NKT00/following{/other_user}", "gists_url": "https://api.github.com/users/NKT00/gists{/gist_id}", "starred_url": "https://api.github.com/users/NKT00/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/NKT00/subscriptions", "organizations_url": "https://api.github.com/users/NKT00/orgs", "repos_url": "https://api.github.com/users/NKT00/repos", "events_url": "https://api.github.com/users/NKT00/events{/privacy}", "received_events_url": "https://api.github.com/users/NKT00/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2023-04-26T23:56:44Z", "updated_at": "2023-04-28T19:19:16Z", "closed_at": null, "author_association": "NONE", "active_lock_reason": null, "body": "### Duplicates\n\n- [X] I have searched the existing issues\n\n### Summary \ud83d\udca1\n\nThere's a few bug reports close to this, but, would it not make sense to get rid of the error\r\n`SYSTEM:  Command get_text_summary returned: Error: This model's maximum context length is 4097 tokens. However, your messages resulted in 5113 tokens. Please reduce the length of the messages.`\r\nby simply swapping model, just for that query, when the length of the query is below the limit for another model? \r\n\r\ngpt-35-turbo is 4096 tokens, whereas the token limits for gpt-4 and gpt-4-32k are 8192 and 32768 respectively. This could be implemented easily.\r\n\r\n\n\n### Examples \ud83c\udf08\n\n_No response_\n\n### Motivation \ud83d\udd26\n\nEverything that pulls a website page fails, as the webpages are too big, generally. However, some are only slightly too big, and could be run through a different model to downsize them first.", "reactions": {"url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3367/reactions", "total_count": 4, "+1": 3, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 1, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3367/timeline", "performed_via_github_app": null, "state_reason": null}