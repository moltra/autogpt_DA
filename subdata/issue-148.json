{"url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3375", "repository_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT", "labels_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3375/labels{/name}", "comments_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3375/comments", "events_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3375/events", "html_url": "https://github.com/Significant-Gravitas/Auto-GPT/pull/3375", "id": 1685977471, "node_id": "PR_kwDOJKSTjM5PQDUU", "number": 3375, "title": "Make prompt parameters configurable", "user": {"login": "DGdev91", "id": 428479, "node_id": "MDQ6VXNlcjQyODQ3OQ==", "avatar_url": "https://avatars.githubusercontent.com/u/428479?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DGdev91", "html_url": "https://github.com/DGdev91", "followers_url": "https://api.github.com/users/DGdev91/followers", "following_url": "https://api.github.com/users/DGdev91/following{/other_user}", "gists_url": "https://api.github.com/users/DGdev91/gists{/gist_id}", "starred_url": "https://api.github.com/users/DGdev91/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DGdev91/subscriptions", "organizations_url": "https://api.github.com/users/DGdev91/orgs", "repos_url": "https://api.github.com/users/DGdev91/repos", "events_url": "https://api.github.com/users/DGdev91/events{/privacy}", "received_events_url": "https://api.github.com/users/DGdev91/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 5410633608, "node_id": "LA_kwDOJKSTjM8AAAABQn-3iA", "url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/labels/size/l", "name": "size/l", "color": "709B6D", "default": false, "description": ""}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2023-04-27T02:14:25Z", "updated_at": "2023-04-28T19:28:00Z", "closed_at": null, "author_association": "NONE", "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/pulls/3375", "html_url": "https://github.com/Significant-Gravitas/Auto-GPT/pull/3375", "diff_url": "https://github.com/Significant-Gravitas/Auto-GPT/pull/3375.diff", "patch_url": "https://github.com/Significant-Gravitas/Auto-GPT/pull/3375.patch", "merged_at": null}, "body": "Loading prompt constraints, resources and performance evaluation from a yaml file (default prompt_settings.yaml) \r\nCan be set from .env (PROMPT_SETTINGS_FILE) or by commandline (--prompt-settings or -P)\r\n\r\n### Background\r\nThe main reason for proposed this changes is because they can help with with different LLM models, we talked about that in #25 #567 #2158.\r\nThey don't handle the prompts in the same way as GPT3.5/GPT4, and they often get confused. this way can be easy to create and share prompts made specifically for them.\r\n\r\nAlso, it can be useful for models made for different languages, like for example https://github.com/FreedomIntelligence/LLMZoo\r\n\r\n....Or just for people who want to have more control on what AutoGPT can do without having to modify the code\r\n\r\n### Changes\r\nMoved the hardcoded default prompt constraints, resources and performance evaluation form prompt.py to the new file prompt_settings.yaml, wich will be used as default file.\r\n\r\nAdded the new configuration variable PROMPT_SETTINGS_FILE in .env.template and modified config.py to handle it\r\n\r\nAdded the new file autogpt/config/prompt_config.py, wich contain the PromptConfig class, wich is initialized passing the file path and contains the datas from the configuration file\r\n\r\nMoved the hardcoded default prompt constraints, resources and performance evaluation form prompt.py to the new file prompt_settings.yaml, wich will be used as default file.\r\n\r\nModified prompt.py to use the values from the PromptConfig instead of hardcoded datas\r\n\r\nModified cli.py, main.py and configurator.py to handle the new --prompt-settings / -P commandline args\r\n\r\n### Documentation\r\nThe new .env variable PROMPT_SETTINGS_FILE is described there, while the new --prompt-settings/-P comd line args are described both in cli.py and in usage.md.\r\nI followed the same policy used for the ai.settings.yaml file\r\n\r\n### Test Plan\r\n- Start AutoGPT without modifying any configurations, should work just as before\r\n- Start AutoGPT using --prompt-settings (file) (ex. python -m autogpt -P prompt_settings_ex.yaml), where file doesn't exists or isn't valid. AutoGPT should give a validation error and stop\r\n- Start AutoGPT using after setting PROMPT_SETTINGS_FILE=(file), where file doesn't exists or isn't valid. AutoGPT should give a validation error and stop\r\n- Copy the prompt_settings.yaml file and change it a bit, while keeping it still valid. Run AutoGPT normally, it should still run as expected\r\n\r\nTo check if the prompt have actually changed, i also used those changes in my fork (see #2594) while connecting to https://github.com/keldenl/gpt-llama.cpp\r\nI know it isn't something officially supported, but it's still a good and quick way to see what's going on, since the webservice prints the prompt on the standard output\r\n\r\n### PR Quality Checklist\r\n- * [x] My pull request is atomic and focuses on a single change.\r\n- * [x] I have thoroughly tested my changes with multiple different prompts.\r\n- * [x] I have considered potential risks and mitigations for my changes.\r\n- * [x] I have documented my changes clearly and comprehensively.\r\n- * [x] I have not snuck in any \"extra\" small tweaks changes <!-- Submit these as separate Pull Requests, they are the easiest to merge! -->\r\n", "reactions": {"url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3375/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/Significant-Gravitas/Auto-GPT/issues/3375/timeline", "performed_via_github_app": null, "state_reason": null}