{
 "cells": [
  {
   "cell_type": "raw",
   "id": "8c4807cf-e90e-495b-9b79-43f7e8ed24cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T21:14:12.769518Z",
     "iopub.status.busy": "2023-05-02T21:14:12.769120Z",
     "iopub.status.idle": "2023-05-02T21:14:14.519023Z",
     "shell.execute_reply": "2023-05-02T21:14:14.518480Z",
     "shell.execute_reply.started": "2023-05-02T21:14:12.769483Z"
    },
    "tags": []
   },
   "source": [
    "from jupysec.rules import Rules\n",
    "\n",
    "Rules().get_findings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1286885b-2979-44cc-b84f-15a1acc4b87b",
   "metadata": {},
   "source": [
    "# Import the requirements and security keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86f33e70-1437-4de5-ba5c-027add165128",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "349925ca-5925-4e45-93c2-9a3449f3b993",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# importing `config.py` to access its variables, not working on windows\n",
    "from config import github_token_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c249e1-308e-42b0-8099-c244421f9d5b",
   "metadata": {
    "tags": []
   },
   "source": [
    "\tpd.options.display.max_columns = 20 #Changes the number of columns diplayed (default is 20) 250\n",
    "\tpd.options.display.max_rows = 60 #Changes the number of rows diplayed (default is 60) 250 \n",
    "\tpd.options.display.max_colwidth = 50 #Changes the number of characters in a cell so that the contents don't get truncated (default is 50) 250"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3391c817-6803-433c-827d-6bfd50deec8a",
   "metadata": {},
   "source": [
    "# Starts the import using the Google API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac76171f-1c14-457b-8906-3181eb462ec7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': 'open', 'per_page': 100, 'page': 1}\n",
      "{'state': 'open', 'per_page': 100, 'page': 2}\n",
      "{'state': 'open', 'per_page': 100, 'page': 3}\n",
      "{'state': 'open', 'per_page': 100, 'page': 4}\n",
      "{'state': 'open', 'per_page': 100, 'page': 5}\n",
      "{'state': 'open', 'per_page': 100, 'page': 6}\n",
      "Retrieved 643 issues from GitHub\n",
      "Response Headers:\n",
      "Server: GitHub.com\n",
      "Date: Wed, 03 May 2023 00:05:46 GMT\n",
      "Content-Type: application/json; charset=utf-8\n",
      "Transfer-Encoding: chunked\n",
      "Cache-Control: private, max-age=60, s-maxage=60\n",
      "Vary: Accept, Authorization, Cookie, X-GitHub-OTP, Accept-Encoding, Accept, X-Requested-With\n",
      "ETag: W/\"119af5862a48a482b940c6129c4773cdce323d2f297ad143da7551663c406c5e\"\n",
      "github-authentication-token-expiration: 2023-07-26 11:35:33 -0400\n",
      "X-GitHub-Media-Type: github.v3; format=json\n",
      "Link: <https://api.github.com/repositories/614765452/issues?state=open&per_page=100&page=6>; rel=\"prev\", <https://api.github.com/repositories/614765452/issues?state=open&per_page=100&page=1>; rel=\"first\"\n",
      "x-github-api-version-selected: 2022-11-28\n",
      "X-RateLimit-Limit: 5000\n",
      "X-RateLimit-Remaining: 4986\n",
      "X-RateLimit-Reset: 1683074597\n",
      "X-RateLimit-Used: 14\n",
      "X-RateLimit-Resource: core\n",
      "Access-Control-Expose-Headers: ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Used, X-RateLimit-Resource, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, X-GitHub-SSO, X-GitHub-Request-Id, Deprecation, Sunset\n",
      "Access-Control-Allow-Origin: *\n",
      "Strict-Transport-Security: max-age=31536000; includeSubdomains; preload\n",
      "X-Frame-Options: deny\n",
      "X-Content-Type-Options: nosniff\n",
      "X-XSS-Protection: 0\n",
      "Referrer-Policy: origin-when-cross-origin, strict-origin-when-cross-origin\n",
      "Content-Security-Policy: default-src 'none'\n",
      "Content-Encoding: gzip\n",
      "X-GitHub-Request-Id: 2719:76B2:2218101:46206B4:6451A55A\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Set the API endpoint URL\n",
    "url = \"https://api.github.com/repos/{owner}/{repo}/issues\"\n",
    "\n",
    "# Set the owner and repo variables   \n",
    "\n",
    "owner = \"Significant-Gravitas\"\n",
    "repo = \"Auto-GPT\"\n",
    "\n",
    "# Set the authentication token (if required)\n",
    "token = github_token_value\n",
    "\n",
    "# Set the query parameters for the API request\n",
    "params = {\n",
    "    \"state\": \"open\",  # retrieve all issues, including closed ones\n",
    "    \"per_page\": 100,  # retrieve up to 100 issues per page\n",
    "    \"page\": 1,  # start with the first page of results\n",
    "}\n",
    "\n",
    "issues = []\n",
    "\n",
    "while True:\n",
    "    response = requests.get(\n",
    "        url.format(owner=owner, repo=repo), params=params, auth=(token, \"\")\n",
    "    )\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(\"Error retrieving issues from GitHub API\")\n",
    "        break\n",
    "\n",
    "    page_issues = response.json()\n",
    "    issues += page_issues\n",
    "\n",
    "    if \"Link\" not in response.headers:\n",
    "        break\n",
    "\n",
    "    link_header = response.headers[\"Link\"]\n",
    "    next_url = None\n",
    "    for link in link_header.split(\",\"):\n",
    "        if 'rel=\"next\"' in link:\n",
    "            next_url = link.split(\";\")[0][1:-1]\n",
    "            break\n",
    "\n",
    "    if next_url is None:\n",
    "        break\n",
    "\n",
    "    print(params)\n",
    "    params[\"page\"] += 1\n",
    "\n",
    "print(f\"Retrieved {len(issues)} issues from GitHub\")\n",
    "\n",
    "# Print the response headers\n",
    "print(\"Response Headers:\")\n",
    "for key, value in response.headers.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de41b406-9ac6-4c06-9c43-72c9be6e5bca",
   "metadata": {},
   "source": [
    "# saves the api response as a dataframe and outputs it various ways for review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4614a143-acb4-41aa-9dd3-55941bc4f43a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create subdirectory if it does not exist\n",
    "if not os.path.exists(\"subdata\"):\n",
    "    os.makedirs(\"subdata\")\n",
    "\n",
    "# loop over issues and save each one as a separate JSON file in the subdirectory\n",
    "for i, issue in enumerate(issues):\n",
    "    filename = (\n",
    "        f\"subdata/issue-{i+1}.json\"  # use the issue number as filename in subdirectory\n",
    "    )\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(issue, f)\n",
    "#   print(f\"Exported JSON to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99c29448-b1ed-449f-b7ef-74bca123513c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Export the resulting JSON to a file\n",
    "with open(\"github-issues.json\", \"w\") as outfile:\n",
    "    json.dump(issues, outfile)\n",
    "\n",
    "# print(\"Exported JSON to github-issues.json\")\n",
    "\n",
    "issues_df = pd.json_normalize(issues)\n",
    "\n",
    "# print(issues_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8038c0f5-f52d-43c1-b99b-5d9d37a1721c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## prints the number of rows in the data frame\n",
    "issues_df.size\n",
    "\n",
    "print(len(issues_df.index))\n",
    "issues_df.to_csv(\"issues_df.csv\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4c673a7d-5e0a-4bfd-93c0-1d4c87786bec",
   "metadata": {
    "tags": []
   },
   "source": [
    "# iterating the columns\n",
    "for col in issues_df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5235312d-9a7a-4e63-86eb-7cf071c0f4f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Makes copies of the issues dataframes for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af30a48b-6ce7-498c-b309-bff38c2bd760",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# copy dataframe\n",
    "issues_title = issues_df.copy(deep=True)\n",
    "issues_body = issues_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "121869b8-6186-493c-a2e4-5f94f690e0e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# removes all the other columns except for the issue number and the body\n",
    "issues_body = issues_body[[\"number\", \"body\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50630565-4e34-4ce9-b71f-e65fe99e2e31",
   "metadata": {
    "tags": []
   },
   "source": [
    "## prints the issue_body data frame if needed\n",
    "print(issues_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091e84c3-bb7a-4dde-b2c3-a737bb8375ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Adds the index of the issues_body dataframe and prints it to verify that the index is working\n",
    "issues_body.reset_index(inplace=True)\n",
    "\n",
    "print(issues_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51b36044-e347-4ec7-84af-97467424b3b5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports the text from the issues template\n",
    "file_name = \"issue_autogpt.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e044bf5-eb31-459c-a492-0c1f68b8ab28",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Starts the text analysis of the body columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "888b4a47-ee4d-4459-acd2-0c74ecb0d0fc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\smsma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloads the lastest punkt nltk library\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ded16d62-24b5-4605-9e8e-752dd365ae67",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# using the template text imported earlier, this cell removes all the template text from the issue body\n",
    "\n",
    "with open(file_name, \"r\", encoding=\"utf-8\") as f:\n",
    "    # Read the file and tokenize it into sentences\n",
    "    text = f.read()\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "    # Convert the sentences into an array\n",
    "    sentences_array = []\n",
    "    for sentence in sentences:\n",
    "        sentence = (\n",
    "            sentence.strip()\n",
    "        )  # Remove whitespace at the beginning and end of the sentence\n",
    "        if sentence:  # Check if the sentence is not empty\n",
    "            #print(sentence)\n",
    "            sentences_array.append(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e49aab-8fdc-4ef6-a40c-64c95157617e",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "### revert issues_body_clean back to original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87265a8-090b-4861-856a-7a498c2d645f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# makes a copy of the issues_body, so that we can compare the 2 or \n",
    "#revert back to the issues_body dataframe without having to rerun multiple cells.\n",
    "\n",
    "issues_body_clean = issues_body.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed15083-aa33-4d6c-8b83-f3a5ce45b06c",
   "metadata": {},
   "source": [
    "## Start removing the template text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7d0ce0-a304-4868-b1e3-6ee5723ec41b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for sentence1 in sentences_array:\n",
    "    issues_body_clean[\"body\"] = issues_body_clean[\"body\"].str.replace(sentence1, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54d14d6-9f4d-43b0-8a20-702eec81ceba",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(sentences_array[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50651ec4-1d3d-406d-8cc5-01ba504ba7c4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "issues_body_clean.info(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b60d0c6-33a3-45d4-b1ad-5348181b2261",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "issues_body_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa9f48c-bf40-4c6c-b060-5c1417ecf8da",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "issues_body_clean_good = issues_body_clean.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78332c6b-42ca-4072-b6f4-a2ced01f3b85",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "issues_body_clean = issues_body_clean_good.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd1214c-0f34-4a10-9205-2ba32863800a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert all non-string columns to string\n",
    "issues_body_clean = issues_body_clean.astype(str)\n",
    "\n",
    "# define a regular expression to match non-alphanumeric and non-space characters\n",
    "regex_unknown = re.compile(r\"[^a-zA-Z0-9\\s]\")\n",
    "\n",
    "# apply the regular expression to each element of the DataFrame\n",
    "issues_body_clean = issues_body_clean.applymap(lambda s: regex_unknown.sub(\" \", s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e75061-5ee2-480b-8bf4-7fb4cb6dfdf9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "issues_body_clean.to_csv(\"issue_body_after_remove.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3c15df-d6d2-4926-a517-0a107f54b1d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in issues_body_clean.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574f9599-7110-4cf4-ad53-c7dad5ce86ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "issues_body_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77edfbb-d55a-4f40-874b-be8e4f4a4c76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "issues_body_clean.to_csv(\"my_data.md\", index=False, columns=[\"body\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee95f39-024f-4c4e-a71c-db3f329ca3d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert all non-string columns to string\n",
    "issues_body_clean = issues_body_clean.astype(str)\n",
    "\n",
    "# define a regular expression to match known characters and markdown syntax\n",
    "regex_known = re.compile(r\"[^\\w\\s.,!?;:\\-'\" r\"\\*\\(\\)\\[\\]#`_\\{\\}\\+\\-\\\\/]|_\")\n",
    "\n",
    "# apply the regular expression to each element of the DataFrame\n",
    "issues_body_clean = issues_body_clean.applymap(lambda s: regex_known.sub(\" \", s))\n",
    "\n",
    "\n",
    "# function to extract phrases from a string\n",
    "def extract_phrases(text, phrase_len):\n",
    "    # split the text into words\n",
    "    words = text.split()\n",
    "    # initialize an empty list to store the phrases\n",
    "    phrases = []\n",
    "    # loop over the words, stopping at the last phrase_len words\n",
    "    for i in range(len(words) - phrase_len + 1):\n",
    "        # extract the phrase of length phrase_len\n",
    "        phrase = \" \".join(words[i : i + phrase_len])\n",
    "        # add the phrase to the list\n",
    "        phrases.append(phrase)\n",
    "    # return the list of phrases\n",
    "    return phrases\n",
    "\n",
    "\n",
    "# set the desired phrase length\n",
    "phrase_len = 3\n",
    "\n",
    "# initialize an empty dictionary to store the phrase counts\n",
    "phrase_counts = {}\n",
    "\n",
    "# loop over each row of the dataframe\n",
    "for index, row in issues_body_clean.iterrows():\n",
    "    # extract the text from the \"body\" column\n",
    "    text = row[\"body\"]\n",
    "    # extract the phrases from the text\n",
    "    phrases = extract_phrases(text, phrase_len)\n",
    "    # loop over the phrases\n",
    "    for phrase in phrases:\n",
    "        # if the phrase is already in the dictionary, increment the count\n",
    "        if phrase in phrase_counts:\n",
    "            phrase_counts[phrase] += 1\n",
    "        # otherwise, add the phrase to the dictionary with a count of 1\n",
    "        else:\n",
    "            phrase_counts[phrase] = 1\n",
    "\n",
    "# create a dataframe from the phrase_counts dictionary\n",
    "phrase_df = pd.DataFrame(list(phrase_counts.items()), columns=[\"phrase\", \"count\"])\n",
    "\n",
    "# sort the dataframe by count in descending order\n",
    "phrase_df = phrase_df.sort_values(\"count\", ascending=False)\n",
    "\n",
    "# print the top 10 phrases\n",
    "print(phrase_df.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf9a62b-57fc-4650-8797-813ff70cef84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b721a0c-3e48-4a88-a08b-07fb7eb70ce0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phrase_df.to_csv(\"phrase.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4530b627-cd82-4fe0-80c5-14e0eb5cee83",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cac6558-55f3-439e-ba34-162e2a4a714c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phrase_DF.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fb2212-17eb-470c-b668-c451c351967e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
